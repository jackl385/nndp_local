{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files ending with `_v1` correspond to the model is the model closest to the one I sent Marc at the end of the semester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "import cloudpickle\n",
    "\n",
    "PATH = Path('/Users/jackli/Documents/Research/nndp_local/investment_stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/jackli/Documents/Research/nndp_local/source_finite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import train, evaluate_policy\n",
    "from model_v1 import u, v_T, m, F, T, nn_to_action\n",
    "from model_v1 import alpha, delta, r, beta, rho, sigma_epsilon\n",
    "from policy_function import make_policy_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4146024105  967050713] [2718843009 1272950319]\n",
      "Objective value on training iteration 43 out of 500: 18.162857055664062"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "key = jax.random.PRNGKey(0)\n",
    "params, policy = make_policy_function(nn_to_action = nn_to_action,\n",
    "                                      key = key,\n",
    "                                      K = 2,\n",
    "                                      P = 1,\n",
    "                                      N_nodes = 256,\n",
    "                                      N_hidden = 3,\n",
    "                                      f_activation = jax.nn.tanh,\n",
    "                                      f_outputs = [jax.nn.relu]\n",
    "                                      )\n",
    "\n",
    "params = train(key = key,\n",
    "               params = params,\n",
    "               policy = policy,\n",
    "               u = u,\n",
    "               v_T = v_T,\n",
    "               m = m,\n",
    "               F = F,\n",
    "               T = T,\n",
    "               N_simul = 1,\n",
    "               batch_size = 1024,\n",
    "               N_iter = 500,\n",
    "               optimizer = optax.adam(1e-3)\n",
    "               )\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the policy function\n",
    "# with open('models/' + str(tag) + '_policy.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(policy, f)\n",
    "\n",
    "# # Save the parameters\n",
    "# with open('models/' + str(tag) + '_params.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the saved policy function\n",
    "# with open('models/' + str(tag) + '_policy.pkl', 'rb') as f:\n",
    "#     policy = cloudpickle.load(f)\n",
    "\n",
    "# # Load the saved parameters\n",
    "# with open('models/' + str(tag) + '_params.pkl', 'rb') as f:\n",
    "#     params = cloudpickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def an_policy(s, policy_params=0): \n",
    "    k = s[:,0]\n",
    "    z = s[:,1]\n",
    "    return (((delta + r) / (alpha * jnp.exp(rho*z + 0.5*sigma_epsilon**2))) ** (1 / (alpha - 1))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Policy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jnp.linspace(-0.4, 0.4)\n",
    "k = jnp.linspace(0.01, 15)\n",
    "\n",
    "k_fixed = 10\n",
    "s_z = jnp.column_stack(([k_fixed]*len(k), z))\n",
    "\n",
    "z_fixed = 0\n",
    "s_k = jnp.column_stack((k, [z_fixed]*len(z)))\n",
    "\n",
    "policy_values_z = policy(s_z, params)\n",
    "an_policy_values_z = an_policy(s_z)\n",
    "policy_pct_error_z = [100 * (list(policy_values_z)[i] / list(an_policy_values_z)[i] - 1) for i in range(len(s_z))]\n",
    "\n",
    "policy_values_k = policy(s_k, params)\n",
    "an_policy_values_k = an_policy(s_k)\n",
    "policy_pct_error_k = [100 * (list(policy_values_k)[i] / list(an_policy_values_k)[i] - 1) for i in range(len(s_k))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "#set 1\n",
    "axs[0][0].plot(z, policy_values_z, label='Policy')\n",
    "axs[0][0].plot(z, an_policy_values_z, label='Analytical Policy')\n",
    "axs[0][0].set_title('Policy: $k = 10$, Vary $z$')\n",
    "axs[0][0].set_xlabel('TFP')\n",
    "axs[0][0].set_ylabel('Capital Next Period')\n",
    "axs[0][0].legend()\n",
    "\n",
    "axs[0][1].plot(z, policy_pct_error_z, label='Policy: Percentage Error')\n",
    "axs[0][1].set_title('% Error for Policy, $k = 10$, Vary $z$')\n",
    "axs[0][1].set_xlabel('TFP')\n",
    "axs[0][1].set_ylabel('Capital Next Period')\n",
    "axs[0][1].axhline(y=0, color='gray', linestyle='--')\n",
    "axs[0][1].legend()\n",
    "\n",
    "#set 3\n",
    "axs[1][0].plot(k, policy_values_k, label='Policy')\n",
    "axs[1][0].plot(k, an_policy_values_k, label='Analytical Policy')\n",
    "axs[1][0].set_title('Policy: $z = 0$, Vary $k$')\n",
    "axs[1][0].set_xlabel('Capital')\n",
    "axs[1][0].set_ylabel('Capital Next Period')\n",
    "axs[1][0].legend()\n",
    "\n",
    "axs[1][1].plot(k, policy_pct_error_k, label='Policy: Percentage Error')\n",
    "axs[1][1].set_title('% Error for Policy, $z = 0$, Vary $k$')\n",
    "axs[1][1].set_xlabel('Capital')\n",
    "axs[1][1].set_ylabel('Capital Next Period')\n",
    "axs[1][1].axhline(y=0, color='gray', linestyle='--')\n",
    "axs[1][1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(PATH+'/figures/'+tag)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "84684bfe7597c1cb2277b05a32b23e8b2ec29bfc48848fa4328c6cefe12cefb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
